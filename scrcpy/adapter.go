package scrcpy

import (
	"bytes"
	"encoding/binary"
	"io"
	"log"
	"net"
	"sync"
	"time"
)

type DataAdapter struct {
	// VideoChanMutex   sync.RWMutex
	// AudioChanMutex   sync.RWMutex
	VideoChan   chan WebRTCFrame
	AudioChan   chan WebRTCFrame
	ControlChan chan WebRTCControlFrame

	// LinearBuffer 管理器
	videoBuffer *LinearBuffer
	audioBuffer *LinearBuffer

	DeviceName string
	VideoMeta  ScrcpyVideoMeta
	AudioMeta  ScrcpyAudioMeta

	// convertVideoPaused bool
	// convertAudioPaused bool

	videoConn   net.Conn
	audioConn   net.Conn
	controlConn net.Conn

	adbClient *ADBClient

	// keyFrameRequestMutex    sync.Mutex
	lastIDRRequestTime time.Time

	keyFrameMutex sync.RWMutex // 保护 LastSPS, LastPPS, LastIDR
	LastVPS       []byte       // 新增：H.265 VPS
	LastSPS       []byte
	LastPPS       []byte
	LastIDR       []byte
	LastIDRTime   time.Time
	// LastPFrames   [][]byte
}

// LinearBuffer 管理器
type LinearBuffer struct {
	buf    []byte
	offset int
	size   int
}

func NewLinearBuffer(size int) *LinearBuffer {
	if size == 0 {
		size = 8 * 1024 * 1024 // 默认 8MB
	}
	return &LinearBuffer{
		buf:  make([]byte, size),
		size: size,
	}
}

// Get 获取一段空闲内存用于写入。如果空间不足，返回 nil
func (lb *LinearBuffer) Get(length int) []byte {
	if lb.offset+length > lb.size {
		return nil
	}
	start := lb.offset
	lb.offset += length
	return lb.buf[start:lb.offset]
}

// 一个DataAdapter对应一个scrcpy实例，通过本地端口建立三个连接：视频、音频、控制
func NewDataAdapter(config map[string]string) (*DataAdapter, error) {
	var err error
	da := &DataAdapter{
		adbClient: NewADBClient(config["device_serial"]),
		// convertVideoPaused: false,
		// convertAudioPaused: false,

		VideoChan:   make(chan WebRTCFrame, 10),
		AudioChan:   make(chan WebRTCFrame, 10),
		ControlChan: make(chan WebRTCControlFrame, 10),

		// 4MB 足够存放几秒的高清视频数据
		// 当这 4MB 用完后，我们会分配新的，旧的由 GC 自动回收
		videoBuffer: NewLinearBuffer(0),
		audioBuffer: NewLinearBuffer(1 * 1024 * 1024), // 1MB 音频缓冲区
	}
	err = da.adbClient.Push(config["server_local_path"], config["server_remote_path"])
	if err != nil {
		log.Fatalf("设置 推送scrcpy-server失败: %v", err)
	}
	err = da.adbClient.Reverse("localabstract:scrcpy", "tcp:"+config["local_port"])
	if err != nil {
		log.Fatalf("设置 Reverse 隧道失败: %v", err)
		return nil, err
	}
	da.adbClient.StartScrcpyServer()
	listener, err := net.Listen("tcp", ":"+config["local_port"])
	if err != nil {
		log.Fatalf("监听端口失败: %v", err)
		return nil, err
	}
	defer listener.Close()
	conns := make([]net.Conn, 3)
	for i := 0; i < 3; i++ {
		conn, err := listener.Accept()
		if err != nil {
			log.Fatalf("Accept 失败: %v", err)
			return nil, err
		}
		log.Println("Accept Connection", i)
		conns[i] = conn
	}

	for i, conn := range conns {
		// The target environment is ARM devices, read directly without buffering could be faster because of less memory copy
		// conn := comm.NewBufferedReadWriteCloser(_conn, 4096)
		switch i {
		case 0:
			// Device Metadata and Video
			err = da.readDeviceMeta(conn)
			if err != nil {
				log.Fatalln("Failed to read device metadata:", err)
				return nil, err
			}
			log.Printf("Connected Device: %s", da.DeviceName)

			da.assignConn(conn)
		case 1:
			da.assignConn(conn)
		case 2:
			// The third connection is always Control
			da.controlConn = conn
			log.Println("Scrcpy Control Connection Established")
		}
	}
	// 甜点值 64KB ~ 128KB
	da.videoConn.(*net.TCPConn).SetReadBuffer(1 * 1024 * 1024)
	da.audioConn.(*net.TCPConn).SetReadBuffer(64 * 1024)

	return da, nil
}

func (da *DataAdapter) Close() {
	if da.videoConn != nil {
		da.videoConn.Close()
	}
	if da.audioConn != nil {
		da.audioConn.Close()
	}
	if da.controlConn != nil {
		da.controlConn.Close()
	}
	da.adbClient.ReverseRemove("localabstract:scrcpy")
	da.adbClient.Stop()
	// close(da.VideoChan)
	// close(da.AudioChan)
}

func (da *DataAdapter) ShowDeviceInfo() {
	log.Printf("Device Name: %s", da.DeviceName)
	log.Printf("Video Codec: %s, Width: %d, Height: %d", da.VideoMeta.CodecID, da.VideoMeta.Width, da.VideoMeta.Height)
	log.Printf("Audio Codec: %s", da.AudioMeta.CodecID)
}

func (da *DataAdapter) StartConvertVideoFrame() {
	go func() {
		var headerBuf [12]byte
		frame := &ScrcpyFrame{}

		isH265 := da.VideoMeta.CodecID == "h265"

		for {
			// read frame header
			if err := readScrcpyFrameHeader(da.videoConn, headerBuf[:], &frame.Header); err != nil {
				log.Println("Failed to read scrcpy frame header:", err)
				return
			}
			// showFrameHeaderInfo(frame.Header)
			frameSize := int(frame.Header.Size)

			// 2. 从 LinearBuffer 获取内存
			payloadBuf := da.videoBuffer.Get(frameSize)
			if payloadBuf == nil {
				// 当前 Buffer 满了，分配一个新的 (旧的会被 GC，只要 WebRTC 发送完)
				// log.Println("Video LinearBuffer full, allocating new chunk")
				da.videoBuffer = NewLinearBuffer(0)
				payloadBuf = da.videoBuffer.Get(frameSize)
				// 极端情况：单帧超过 4MB (几乎不可能)，直接分配独立内存
				if payloadBuf == nil {
					payloadBuf = make([]byte, frameSize)
				}
			}

			if _, err := io.ReadFull(da.videoConn, payloadBuf); err != nil {
				log.Println("Failed to read video frame payload:", err)
				return
			}
			frameData := payloadBuf
			// if da.VideoMeta.CodecID == "h264" {
			// 	niltype := frameData[4] & 0x1F
			// 	log.Printf("(h264) NALU Type of first NALU in frame: %d; total size: %d", niltype, len(frameData))
			// } else {
			// 	niltype := (frameData[4] >> 1) & 0x3F
			// 	log.Printf("(h265) NALU Type of first NALU in frame: %d; total size: %d", niltype, len(frameData))
			// }

			var iter func(func(WebRTCFrame) bool)
			if isH265 {
				iter = da.GenerateWebRTCFrameH265(frame.Header, frameData)
			} else {
				iter = da.GenerateWebRTCFrameH264(frame.Header, frameData)
			}

			for webRTCFrame := range iter {
				select {
				case da.VideoChan <- webRTCFrame:
				default:
					log.Println("Video channel full, waiting to send frame...")
					da.VideoChan <- webRTCFrame
				}
			}
		}
	}()
}

func (da *DataAdapter) StartConvertAudioFrame() {
	go func() {
		var headerBuf [12]byte
		frame := &ScrcpyFrame{}
		for {
			// read frame header
			if err := readScrcpyFrameHeader(da.audioConn, headerBuf[:], &frame.Header); err != nil {
				log.Println("Failed to read scrcpy audio frame header:", err)
				return
			}
			// log.Printf("Audio Frame Timestamp: %v, Size: %v isConfig: %v\n", frame.Header.PTS, frame.Header.Size, frame.Header.IsConfig)
			frameSize := int(frame.Header.Size)
			payloadBuf := da.audioBuffer.Get(frameSize)
			if payloadBuf == nil {
				// log.Println("Audio LinearBuffer full, allocating new chunk")
				da.audioBuffer = NewLinearBuffer(1 * 1024 * 1024)
				payloadBuf = da.audioBuffer.Get(frameSize)
				if payloadBuf == nil {
					payloadBuf = make([]byte, frameSize)
				}
			}

			// read frame payload
			n, _ := io.ReadFull(da.audioConn, payloadBuf)
			frameData := payloadBuf

			if frame.Header.IsConfig {
				log.Println("Audio Config Frame Received")

				totalLen := 7 + 8 + int(n)
				configBuf := make([]byte, totalLen) // Config 帧很少，直接分配

				copy(configBuf[0:7], []byte("AOPUSHC"))                   // Magic
				binary.LittleEndian.PutUint64(configBuf[7:15], uint64(n)) // Length
				copy(configBuf[15:], frameData)
				da.AudioChan <- WebRTCFrame{
					Data:      configBuf,
					Timestamp: int64(frame.Header.PTS),
				}
				continue
			}

			// 这里的 Data 引用了 LinearBuffer 中的内存，零拷贝
			webRTCFrame := WebRTCFrame{
				Data:      frameData,
				Timestamp: int64(frame.Header.PTS),
			}
			select {
			case da.AudioChan <- webRTCFrame:

			default:
				log.Println("Audio channel full, waiting to send frame...")
				da.AudioChan <- webRTCFrame
			}
		}
	}()
}

func (da *DataAdapter) assignConn(conn net.Conn) error {
	codecID := ReadCodecID(conn)
	switch codecID {
	case "h264", "h265", "av1 ":
		da.videoConn = conn
		da.VideoMeta.CodecID = codecID
		err := da.readVideoMeta(conn)
		if err != nil {
			log.Fatalln("Failed to read video metadata:", err)
			return err
		}
		log.Println("Scrcpy Video Connection Established")
	case "aac ", "opus":
		da.audioConn = conn
		da.AudioMeta.CodecID = codecID
		log.Println("Audio Connection Established")
	default:
		da.controlConn = conn
		log.Println("Scrcpy Control Connection Established")
	}
	return nil
}

func (da *DataAdapter) readDeviceMeta(conn net.Conn) error {
	// 1. Device Name (64 bytes)
	nameBuf := make([]byte, 64)
	_, err := io.ReadFull(conn, nameBuf)
	if err != nil {
		return err
	}
	da.DeviceName = string(nameBuf)
	return nil
}

func ReadCodecID(conn net.Conn) string {
	// Codec ID (4 bytes)
	codecBuf := make([]byte, 4)
	if _, err := io.ReadFull(conn, codecBuf); err != nil {
		log.Println("Failed to read codec ID:", err)
		return ""
	}

	return string(codecBuf)
}

func (da *DataAdapter) readVideoMeta(conn net.Conn) error {
	// Width (4 bytes)
	// Height (4 bytes)
	// Codec 已经在外面读取过了，用于确认是哪个通道
	metaBuf := make([]byte, 8)
	if _, err := io.ReadFull(conn, metaBuf); err != nil {
		log.Println("Failed to read metadata:", err)
		return err
	}
	// 解析元数据
	da.VideoMeta.Width = binary.BigEndian.Uint32(metaBuf[0:4])
	da.VideoMeta.Height = binary.BigEndian.Uint32(metaBuf[4:8])

	return nil
}

func (da *DataAdapter) updateVideoMetaFromSPS(sps []byte, codec string) {
	if da.LastSPS != nil && bytes.Equal(da.LastSPS, sps) {
		// log.Println("SPS unchanged, no need to update video meta")
		return
	}
	var spsInfo SPSInfo
	var err error
	switch codec {
	case "h264":
		spsInfo, err = ParseSPS_H264(sps, true)
	case "h265":
		spsInfo, err = ParseSPS_H265(sps)
	default:
		log.Println("Unknown codec type for SPS parsing:", codec)
		return
	}

	if err != nil {
		log.Println("Failed to parse SPS for video meta update:", err)
		return
	}
	da.VideoMeta.Width = spsInfo.Width
	da.VideoMeta.Height = spsInfo.Height
	log.Printf("Updated Video Meta from SPS: Width=%d, Height=%d", da.VideoMeta.Width, da.VideoMeta.Height)
}

// func (da *DataAdapter) cacheFrame(webrtcFrame *WebRTCFrame, frameType string) {
// 	switch frameType {
// 	case "SPS":
// 		da.keyFrameMutex.Lock()

// }

func readScrcpyFrameHeader(conn net.Conn, headerBuf []byte, header *ScrcpyFrameHeader) error {
	if _, err := io.ReadFull(conn, headerBuf); err != nil {
		return err
	}

	ptsAndFlags := binary.BigEndian.Uint64(headerBuf[0:8])
	packetSize := binary.BigEndian.Uint32(headerBuf[8:12])

	// 提取标志位
	isConfig := (ptsAndFlags & 0x8000000000000000) != 0
	isKeyFrame := (ptsAndFlags & 0x4000000000000000) != 0

	// 提取PTS (低62位)
	pts := uint64(ptsAndFlags & 0x3FFFFFFFFFFFFFFF)
	header.IsConfig = isConfig
	header.IsKeyFrame = isKeyFrame
	header.PTS = pts
	header.Size = packetSize
	return nil
}

func showFrameHeaderInfo(header ScrcpyFrameHeader) {
	log.Printf("Frame Header - PTS: %d, Size: %d, IsConfig: %v, IsKeyFrame: %v",
		header.PTS, header.Size, header.IsConfig, header.IsKeyFrame)
}

func createCopy(src []byte) []byte {
	if len(src) == 0 {
		log.Println("createCopy called with empty src")
		return nil
	}
	dst := make([]byte, len(src))
	copy(dst, src)
	return dst
}
